{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f02e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/drryodino246/csc542-gp-team164.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3682da4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0700f22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "emotions = load_dataset('csv', data_files='/content/csc542-gp-team164/baseline.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0944426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_split = emotions['train'].train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = emotions_split['train']\n",
    "test_dataset = emotions_split['test']\n",
    "\n",
    "print(f\"Training data size: {len(train_dataset)}\")\n",
    "print(f\"Test data size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c6f8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Build-From-Scratch version ###\n",
    "\n",
    "from datasets import load_dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# ラベルエンコード\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels = label_encoder.fit_transform(train_dataset['updated_emotion'])\n",
    "test_labels = label_encoder.transform(test_dataset['updated_emotion'])\n",
    "\n",
    "# トークナイズ（今回は簡易的に単語単位で分割）\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")  # Tokenizerだけ使う\n",
    "\n",
    "MAX_LEN = 64  # 短文ならこれで充分\n",
    "\n",
    "def tokenize(texts):\n",
    "    return tokenizer(texts, padding='max_length', truncation=True, max_length=MAX_LEN, return_tensors='pt')\n",
    "\n",
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.encodings = tokenize(texts)\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.encodings['input_ids'][idx],\n",
    "            'label': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_data = EmotionDataset(train_dataset['text'], train_labels)\n",
    "test_data = EmotionDataset(test_dataset['text'], test_labels)\n",
    "\n",
    "###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3bf2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Build-From-Scratch version ###\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TextCNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_classes, kernel_sizes=[3,4,5], num_filters=100):\n",
    "        super(TextCNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(1, num_filters, (k, embed_dim)) for k in kernel_sizes\n",
    "        ])\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(num_filters * len(kernel_sizes), num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  # (batch_size, seq_len, embed_dim)\n",
    "        x = x.unsqueeze(1)  # (batch_size, 1, seq_len, embed_dim)\n",
    "        conv_x = [F.relu(conv(x)).squeeze(3) for conv in self.convs]  # conv outputs\n",
    "        pooled_x = [F.max_pool1d(c, c.size(2)).squeeze(2) for c in conv_x]\n",
    "        out = torch.cat(pooled_x, dim=1)\n",
    "        out = self.dropout(out)\n",
    "        return self.fc(out)\n",
    "    \n",
    "###################################    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e13b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb2765d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_glove_embeddings(file_path):\n",
    "    embeddings = {}\n",
    "    with open(file_path, 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            word = parts[0]\n",
    "            vector = np.array(parts[1:], dtype=np.float32)\n",
    "            embeddings[word] = vector\n",
    "    return embeddings\n",
    "\n",
    "glove_path = \"/content/glove.6B.100d.txt\"\n",
    "glove_embeddings = load_glove_embeddings(glove_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430a29a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from collections import Counter\n",
    "import torch\n",
    "\n",
    "# Colab上でデータから語彙を作る\n",
    "def yield_tokens(texts):\n",
    "    for text in texts:\n",
    "        yield text.lower().split()\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_dataset['text']), specials=[\"<pad>\", \"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# GloVe埋め込みをvocabに合わせて並べる\n",
    "embedding_dim = 100\n",
    "embedding_matrix = np.random.normal(scale=0.6, size=(vocab_size, embedding_dim))\n",
    "\n",
    "for i, token in enumerate(vocab.get_itos()):\n",
    "    vector = glove_embeddings.get(token)\n",
    "    if vector is not None:\n",
    "        embedding_matrix[i] = vector\n",
    "\n",
    "embedding_matrix = torch.tensor(embedding_matrix, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9d2b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(nn.Module):\n",
    "    def __init__(self, embedding_matrix, num_classes, kernel_sizes=[3,4,5], num_filters=100):\n",
    "        super(TextCNN, self).__init__()\n",
    "        vocab_size, embed_dim = embedding_matrix.shape\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=False)  # ← ここ大事！\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(1, num_filters, (k, embed_dim)) for k in kernel_sizes\n",
    "        ])\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(num_filters * len(kernel_sizes), num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  # (batch, seq_len, embed_dim)\n",
    "        x = x.unsqueeze(1)     # (batch, 1, seq_len, embed_dim)\n",
    "        conv_x = [F.relu(conv(x)).squeeze(3) for conv in self.convs]\n",
    "        pooled_x = [F.max_pool1d(c, c.size(2)).squeeze(2) for c in conv_x]\n",
    "        out = torch.cat(pooled_x, dim=1)\n",
    "        out = self.dropout(out)\n",
    "        return self.fc(out)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
